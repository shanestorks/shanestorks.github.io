---
---

@inproceedings{storks2021tieredreasoning,
      title={Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding},
      author={Shane Storks and Qiaozi Gao and Yichi Zhang and Joyce Chai},
      year={2021},
      abstract={Large-scale, pre-trained language models (LMs) have achieved human-level performance on a breadth of language understanding tasks. However, evaluations only based on end task performance shed little light on machines' true ability in language understanding and reasoning. In this paper, we highlight the importance of evaluating the underlying reasoning process in addition to end performance. Toward this goal, we introduce Tiered Reasoning for Intuitive Physics (TRIP), a novel commonsense reasoning dataset with dense annotations that enable multi-tiered evaluation of machines' reasoning process. Our empirical results show that while large LMs can achieve high end performance, they struggle to support their predictions with valid supporting evidence. The TRIP dataset and our baseline results will motivate verifiable evaluation of commonsense reasoning and facilitate future research toward developing better language understanding and reasoning models.},
      booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021}
      arxiv={https://arxiv.org/abs/2109.04947},
      code={https://github.com/sled-group/Verifiable-Coherent-NLU}
}

@inproceedings{storks2021assessingcoherence,
      title={Beyond the Tip of the Iceberg: Assessing Coherence of Text Classifiers},
      author={Shane Storks and Joyce Chai},
      year={2021},
      abstract={As large-scale, pre-trained language models achieve human-level and superhuman accuracy on existing language understanding tasks, statistical bias in benchmark data and probing studies have recently called into question their true capabilities. For a more informative evaluation than accuracy on text classification tasks can offer, we propose evaluating systems through a novel measure of prediction coherence. We apply our framework to two existing language understanding benchmarks with different properties to demonstrate its versatility. Our experimental results show that this evaluation framework, although simple in ideas and implementation, is a quick, effective, and versatile measure to provide insight into the coherence of machines' predictions.},
      booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021}
      arxiv={https://arxiv.org/abs/2109.04922},
      code={https://github.com/sled-group/Verifiable-Coherent-NLU}
}

@inproceedings{storks2021learningtolocalize,
      title={Are We There Yet? Learning to Localize in Embodied Instruction Following},
      author={Shane Storks and Qiaozi Gao and Govind Thattai and Gokhan Tur},
      year={2021},
      abstract={Embodied instruction following is a challenging problem requiring an agent to infer a sequence of primitive actions to achieve a goal environment state from complex language and visual inputs. Action Learning From Realistic Environments and Directives (ALFRED) is a recently proposed benchmark for this problem consisting of step-by-step natural language instructions to achieve subgoals which compose to an ultimate high-level goal. Key challenges for this task include localizing target locations and navigating to them through visual inputs, and grounding language instructions to visual appearance of objects. To address these challenges, in this study, we augment the agent's field of view during navigation subgoals with multiple viewing angles, and train the agent to predict its relative spatial relation to the target location at each timestep. We also improve language grounding by introducing a pre-trained object detection module to the model pipeline. Empirical studies show that our approach exceeds the baseline model performance.},
      booktitle={Hybrid AI Workshop @ AAAI 2021},
      arxiv={https://arxiv.org/abs/2101.03431},
      slides={https://docs.google.com/presentation/d/1CPUarpE7t_ip85iAQkRoJ1Gw1fdoEmOm/edit?usp=sharing&ouid=109898908954021199155&rtpof=true&sd=true}
}

@article{storks2020recentadvances,
      title={Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches}, 
      author={Shane Storks and Qiaozi Gao and Joyce Y. Chai},
      year={2020},
      abstract={In the NLP community, recent years have seen a surge of research activities that address machines' ability to perform deep language understanding which goes beyond what is explicitly stated in text, rather relying on reasoning and knowledge of the world. Many benchmark tasks and datasets have been created to support the development and evaluation of such natural language inference ability. As these benchmarks become instrumental and a driving force for the NLP research community, this paper aims to provide an overview of recent benchmarks, relevant knowledge resources, and state-of-the-art learning and inference approaches in order to support a better understanding of this growing field.},
      journal={arXiv:1904.01172 [cs.CL]},
      arxiv={https://arxiv.org/abs/1904.01172},   
}